{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Understanding the foundations of tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Gaurav-Pande/MLCC/blob/master/Understanding_the_foundations_of_tensorflow.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "nXZBOS_pHKKe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Understanding Foundations of tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "p5XO8B61385t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Basics\n",
        "\n",
        "### Supervised ML algorithms:\n",
        "\n",
        "* Suppose we have input variable x and output variable y\n",
        "\n",
        "* Supervised machine learning algorithm task is to find a mapping function such that we can predict the \n",
        "   value of y with input x, that is : y = f(x). finding mapping function f is called supervised learning\n",
        "   \n",
        " * Approximate the learning function f, such that new values of x can be predict the value of y.\n",
        " \n",
        " * we use existing training dataset to correct the mapping function approximation. \n",
        " \n",
        " \n",
        " ### Unsupervised ML algorithms:\n",
        " \n",
        " * Here we have input variable x but no output variable y.\n",
        " \n",
        " * The goal of the algo is the find the model or pattern within the data to learn more about data and make prediction \n",
        " \n",
        " *  there is no supervision here, algorithms have to work on their own to make predictions.\n",
        " \n",
        " \n",
        " ### Deep Learning:\n",
        " \n",
        " * **Traditional** ml based systems will rely on experts to decide what features to pay attention to. For example you will see in the linear regression problem, we have feed random value of A and b in equation: y = Ax + b, and get the best/optimized value of A,b so that the line is closest to all the datapoints\n",
        " \n",
        " * **Representation** based ml system figure out by themselves what features to pay attention to.\n",
        " In the linear regression scenario the Representation system will able to pickup from a random value and optimized by itself to get the optimized value of A, b. \n",
        " \n",
        " \n",
        " * **Deep Learning** systems are one type of representation systems\n",
        " \n",
        " ### Deep Learning and Neural Networks:\n",
        " \n",
        " * **Deep learning** : Algorithms which learns what feature matters\n",
        " \n",
        " * **Neural networks**:  Neural Networks are the most common class of deep learning algorithms\n",
        " \n",
        " * **Neurons**: Simple building blocks that actually learn by themselves\n",
        " \n",
        " * **TensorFlow**: TensorFLow is an open source software library for numerical computations using Data\n",
        " flow graphs.\n",
        " \n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "BDLh2TJAHEad",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8hXgmPU0Hi21",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Points to remember\n",
        "\n",
        "* In tesorflow every problem in the world can be described in terms of a directly acyclic graph\n",
        "* First we build a graph in tensorflow, so that the tensorflow have the knowledge of the whole graph and an understanding which parts of the graph are independent and can be run parallely in a distributed scenario(In different GPUs and CPUs)\n",
        "* Each node in the graph is called compute node and the edges connecting the nodes are known as tensors.\n",
        "* Output of one tensor is feeded to the input of the next node.\n",
        "![Image](https://github.com/Gaurav-Pande/MLCC/blob/master/tensorflow_basics/assets/1.png)\n",
        "* Than we initiate a session to execute the graph.\n",
        "* And than finally we can run each nodes in the graph and can see their output.\n",
        "* remember untill the session is not initialized, the graph will not executed.\n"
      ]
    },
    {
      "metadata": {
        "id": "OyAs7lDMJR2O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Define constants or compute nodes first"
      ]
    },
    {
      "metadata": {
        "id": "TwNGWnJPHgAk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# These are the inputs that will be feeded to compute nodes\n",
        "a = tf.constant(6.5, name = 'constant_a')\n",
        "b = tf.constant(3.4, name = 'constant_b')\n",
        "c = tf.constant(3.0, name = 'constant_c')\n",
        "d = tf.constant(100.2, name = 'constant_d')\n",
        "\n",
        "# Now lets define some compute nodes\n",
        "square = tf.square(a, name = 'square_of_a')\n",
        "power = tf.pow(b,c, name = 'power_of_b_to_c')\n",
        "sqrt = tf.sqrt(d, name = 'square_root_of_d')\n",
        "\n",
        "#Now lets define the final node.\n",
        "final_node = tf.add_n([square,power,sqrt], name = 'final_node')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PuKT3fQGRnPN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Now we initialize the session"
      ]
    },
    {
      "metadata": {
        "id": "b_5_4qUbQHpp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iQDjpGCnRxQM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Now we can execute the nodes in the graph"
      ]
    },
    {
      "metadata": {
        "id": "8ZD_w0sjRumb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print (\"Square of a is:\",sess.run(square))\n",
        "print (\"b to the power c is :\",sess.run(power))\n",
        "print (\"square root of d is:\",sess.run(sqrt))\n",
        "print (\"final result of all the nodes computation is:\", sess.run(final_node))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YlW1HS3PSHIn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "writer = tf.summary.FileWriter('/tmp/m2_example',sess.graph)\n",
        "writer.close\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ARJBuXK1dso",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Tensor: What it is?\n",
        "* A tensor is the basic unit in the tensorflow, all the input that we feed into the graph are called tensors.\n",
        "* A tensor is of primitive type shaped into an array of any dimensions.\n",
        "##### Properties of a tensor:\n",
        "  * Rank: the number of dimensions in a tensor. Scaler(like 2,\"a\") have 0D tensor, [1,2,3] is 1-D tensor(basically number of square breacket pairs is the dimensionality of  a tensor)\n",
        "  * Shape: It the number of elements in a tensor.e.g: [1,2]--> shape is [2]. [[1,2],[3,4]]--> shape si [2,2]\n",
        "  * Datatype: the data type of the tensor\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "u_hDNMAD2hLs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zeroD = tf.constant(1,name=\"0_d_tensor\")\n",
        "# again initialize a session\n",
        "sess = tf.Session()\n",
        "sess.run(tf.rank(zeroD))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "30QkVC_i3w1P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tensor Math"
      ]
    },
    {
      "metadata": {
        "id": "V_7Fote1ilvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import tensorflow\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "brHKk7b54LQh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define tensors\n",
        "x = tf.constant([100,200,300], name = 'tensor_x')\n",
        "y = tf.constant([1,2,3],name = 'tensor_y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ftw5oiRh4fH-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define computation nodes\n",
        "sum_x = tf.reduce_sum(x,name='sum_x')\n",
        "prod_y = tf.reduce_prod(y,name = 'prod_y')\n",
        "final_div =  tf.div(sum_x,prod_y, name='final_div')\n",
        "\n",
        "# we can define the tensors on the fly as well\n",
        "final_mean = tf.reduce_mean([sum_x,prod_y],name='final_mean')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KvIVulOH5RRO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# inititalize session\n",
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzxHMPEq5cFV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# execute the graph\n",
        "print (\"x\",sess.run(sum_x))\n",
        "print ('final_mean',sess.run(final_mean))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dFV1gujm5n6r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_4ku-2b6E_1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Numpy and Tensor\n",
        "\n",
        "* python accepts tensors and numpy arrays exactly the same. in fact tf.int32 == np.int32\n"
      ]
    },
    {
      "metadata": {
        "id": "QL6-3vQG6yLZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QGe86T6Z63_Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zeroD = np.array(30, dtype=np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tys5Txkr7EC2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5DO_kkXK7JL2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.rank(zeroD))\n",
        "sess.run(tf.shape(zeroD))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G8d3UUOrRE5k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Linear Regression\n"
      ]
    },
    {
      "metadata": {
        "id": "QLaozNwRRPQ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Points to Remember\n",
        "* Linear Regression is the classic example of supervised learning.\n",
        "* Linear Regression can be represented by y = Ax + b\n",
        "* In Ml it is more about finding the best fit line, ie the line which is closest to all the points on the dataset.\n",
        "* Minimizing least square error is the way to find the best fit line. In this method you drop verticle lines from all the points to the line or equation you are inspecting, and the best fit line is that line which has least sum of squares of length of those vertical lines."
      ]
    },
    {
      "metadata": {
        "id": "i7YPlAbKUW6t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Linear Regression Algorithm \n",
        "\n",
        "* equation of line: Y = Ax + B\n",
        "* we start by estimating some value of A and B.\n",
        "* Find the errors for the regression line with those values of A and B.\n",
        "* feed error back to get the new value of the A and B."
      ]
    },
    {
      "metadata": {
        "id": "mFEvSz_1VQqD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Placeholders\n",
        "\n",
        "* It holds the value of the tensors, whose value will be available only at runtime.\n"
      ]
    },
    {
      "metadata": {
        "id": "ZXA8PZdDWHnp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gEWMQm2FWJwJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining a placeholder\n",
        "x = tf.placeholder(tf.int32, shape = [3], name = 'x')\n",
        "y = tf.placeholder(tf.int32, shape = [3], name = 'y')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-zg75LXXWesU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define Nodes\n",
        "sum_x = tf.reduce_sum(x, name='sum_x')\n",
        "prod_y = tf.reduce_prod(y, name='prod_y')\n",
        "final_div = tf.div(sum_x,prod_y, name='final_div')\n",
        "final_mean = tf.reduce_mean([sum_x,prod_y],name='final_mean')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FUGlD0zdXBQ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " #Initiate a session\n",
        "  sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S9aFK3RWXImr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now compute the nodes\n",
        "# Notice now how we are feeding the input via feed dictionary method in placeholder\n",
        "print(\"sum of values of x\", sess.run(sum_x, feed_dict = {x : [100,2,3]}))\n",
        "print(\"prod of values of y\", sess.run(prod_y, feed_dict = {y: [1,2,3]}))\n",
        "print(\"final dic result:\", sess.run(final_mean, feed_dict = {x:[2,3,4], y:[5,6,7]}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hAboTtdheXte",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wPq989WEeK0E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### fetches and feed dictionary\n",
        "\n",
        "* we feed the values of the placeholder using feed_dict inplace parameter"
      ]
    },
    {
      "metadata": {
        "id": "a9De04WneQBR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# y = Wx + b\n",
        "\n",
        "W = tf.constant([100,200],name='constant_W')\n",
        "\n",
        "# define a place holder for x and b, note that placeholder can store tensors of\n",
        "# any shape\n",
        "\n",
        "x = tf.placeholder(tf.int32, name='x')\n",
        "b = tf.placeholder(tf.int32, name='b')\n",
        "\n",
        "Wx = tf.multiply(W,x, name='Wx')\n",
        "\n",
        "y = tf.add(Wx, b, name='y')\n",
        "\n",
        "# rather than initializing session and closing everytime, we will use the loop\n",
        "#\n",
        "with tf.Session() as sess:\n",
        "  print (\"Results are as:\", sess.run(fetches=y, feed_dict = {Wx : [1,2], b : [1,2]}))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QJYbakN5is72",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Variables\n",
        "\n",
        "* we know that in linear regression we start of by some value so A and b and than we tweak these values using feedback value, that means the value stored in A and b will keep on changing when we will run the algorithm, that is where variable are usefull.\n",
        "\n",
        "#### In summary:\n",
        "  * constants: immutable values whose value doesnt change.\n",
        "  * placeholder: assigned once during runtime  and do not change after.\n",
        "  * variable: constantly recomputed as the graph is recomputed.\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "0f2102Qdjx5A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# y = Wx + b\n",
        "\n",
        "W = tf.Variable([1.0, 2.0], tf.float32, name='var_W')\n",
        "\n",
        "# define a place holder for x and b, note that placeholder can store tensors of\n",
        "# any shape\n",
        "\n",
        "x = tf.placeholder(tf.float32, name='x')\n",
        "b = tf.Variable([1.0,2.0], tf.float32, name='b')\n",
        "\n",
        "y = W*x + b\n",
        "\n",
        "## remember to initialize the variable, also note that is also a computation node\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# rather than initializing session and closing everytime, we will use the loop\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  print (\"Results are as:\", sess.run(fetches=y, feed_dict = {x: [5.0, 6.0]}))\n",
        "  \n",
        "  \n",
        "  \n",
        "s = W*x\n",
        "\n",
        "# Here i am only initializing the variables i need \n",
        "init = tf.variables_initializer([W])\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  print (\"Results are as:\", sess.run(fetches=s, feed_dict = {x: [5.0, 6.0]}))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hOI97D2pm_8N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Default and Explicitly Specified Graph\n",
        "\n",
        "* In all the programs that we have written above we are using the implicit default graph\n",
        "* We can instantiate our own graph and perform all actions there as well."
      ]
    },
    {
      "metadata": {
        "id": "R1kXnkYMnvAL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "g1 = tf.Graph()\n",
        "\n",
        "with g1.as_default():\n",
        "\twith tf.Session() as sess:\n",
        "\t\t# y = Ax + b\n",
        "\t\tA = tf.constant([5, 7], tf.int32, name='A')\n",
        "\n",
        "\t\tx = tf.placeholder(tf.int32, name='x')\n",
        "\t\tb = tf.constant([3, 4], tf.int32, name='b')\n",
        "\n",
        "\t\ty = A * x + b\n",
        "\n",
        "\t\tprint (sess.run(y, feed_dict={x: [10, 100]}))\n",
        "\n",
        "\t\tassert y.graph is g1\n",
        "\n",
        "g2 = tf.Graph()\n",
        "with g2.as_default():\n",
        "\twith tf.Session() as sess:\n",
        "\t\t# y = A^x\n",
        "\t\tA = tf.constant([5, 7], tf.int32, name='A')\n",
        "\n",
        "\t\tx = tf.placeholder(tf.int32, name='x')\n",
        "\n",
        "\t\ty = tf.pow(A, x, name=\"y\")\n",
        "\n",
        "\t\tprint (sess.run(y, feed_dict={x: [3, 5]}))\n",
        "\n",
        "\t\tassert y.graph is g2\n",
        "\n",
        "default_graph = tf.get_default_graph()\n",
        "with tf.Session() as sess:\n",
        "\t# y = A + x\n",
        "\tA = tf.constant([5, 7], tf.int32, name='A')\n",
        "\n",
        "\tx = tf.placeholder(tf.int32, name='x')\n",
        "\n",
        "\ty = A + x\n",
        "\tprint (sess.run(y, feed_dict={x: [3, 5]}))\n",
        "\n",
        "\tassert y.graph is default_graph\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rND3xOL2qrfl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Named Scopes\n",
        "\n",
        "* named scopes are to categorize the computations in the tensor board graph so that it becomes easy for us to debug and understand the graph.\n",
        "\n",
        "* without named scope the graph can go messy and complicated.\n",
        "\n",
        "* you can also say that these are cetain blocks of code that you want to debug separatly using tensorboard\n"
      ]
    },
    {
      "metadata": {
        "id": "vCRSnL7VrNAE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "A = tf.constant([4], tf.int32, name='A')\n",
        "B = tf.constant([5], tf.int32, name='B')\n",
        "C = tf.constant([6], tf.int32, name='C')\n",
        "\n",
        "x = tf.placeholder(tf.int32, name='x')\n",
        "\n",
        "# y = Ax^2 + Bx + C\n",
        "with tf.name_scope(\"Equation_1\"):\n",
        "\tAx2 = tf.multiply(A, tf.pow(x, 2), name=\"Ax2\")\n",
        "\tBx = tf.multiply(B, x, name=\"Bx\")\n",
        "\ty1 = tf.add_n([Ax2, Bx, C], name=\"calc_1\")\n",
        "\n",
        "# y = Ax^2 + Bx^2\n",
        "with tf.name_scope(\"Equation_2\"):\n",
        "\tAx2 = tf.multiply(A, tf.pow(x, 2), name=\"Ax2\")\n",
        "\tBx2 = tf.multiply(B, tf.pow(x, 2), name=\"Bx2\")\n",
        "\ty2 = tf.add_n([Ax2, Bx2], name=\"calc_1\")\n",
        "\n",
        "with tf.name_scope(\"Final_Sum\"):\n",
        "\ty = y1 + y2\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\tprint (sess.run(y, feed_dict={x: [10]}))\n",
        "\n",
        "\twriter = tf.summary.FileWriter('./tensorboard_file', sess.graph)\n",
        "\twriter.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DyrzYniCuIfj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Write a Basic Linear Regression model"
      ]
    },
    {
      "metadata": {
        "id": "jeKi1h77uOve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Model parameters\n",
        "W = tf.Variable([0.3],dtype = tf.float32, name='var_W')\n",
        "b = tf.Variable([0.1],dtype = tf.float32, name='var_b')\n",
        "\n",
        "# Model input and ouput\n",
        "x = tf.placeholder(tf.float32)\n",
        "linear_model = W*x + b\n",
        "\n",
        "y = tf.placeholder(tf.float32)\n",
        "\n",
        "# define your loss function\n",
        "loss = tf.reduce_sum(tf.square(linear_model - y))\n",
        "\n",
        "# Define an optimizer which will try to optimize the algorithm\n",
        "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
        "\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "# train  data\n",
        "\n",
        "x_train = [1,2,3,4]\n",
        "y_train = [0,-1,-2,-3]\n",
        "\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for i in range(1000):\n",
        "    sess.run(train, {x:x_train, y:y_train})\n",
        "\n",
        "    # Now evaluate the training accuracy\n",
        "    curr_W, curr_b, curr_loss = sess.run([W,b,loss],{x:x_train, y:y_train})\n",
        "    \n",
        "  print(\"w:\",curr_W)\n",
        "  print(\"b:\",curr_b)\n",
        "  print(\"loss:\",curr_loss)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aWXx7nkmysZ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Image Recognition\n",
        "\n",
        "\n",
        "* Every image is made up of millions of pixels which contains information like saturation, hue, grayscale etc.\n",
        "\n",
        "* Each pixel holds a value based on the image, e.g wether it is a grayscale image or RGB\n",
        "\n",
        "* in a colour image, every pixel is a RGB value(Redm Green, Blue)-- how mch each of these component is present in each pixel.\n",
        "\n",
        "* Each of these values will be present from range 0-255. For example: Red pixel would be represented as [255,0,0]\n",
        "\n",
        "* Grayscale images contains shades from white to black but no colour. In a gray scale image every pixel contain one value which is the intensity of that perticular pixel from range 0.0.-1.0.\n",
        "\n",
        "* An image is nothing but a 2D matrix, that is x and y cordinates of each pixel in the screen, but in addition to it we also need to hold the pixel value as well.\n",
        "\n",
        "* So the number of channel specifies the number of elements in the third dimension. In case of gray scale image the 3rd dimension will contain a single channel or single value while a coloured image will contains the 3rd dimension as the RGB value. \n",
        "\n",
        "* So that means shape of the image contains 2 values (val1,val2,val3), where val1 is width of the image and val2 is the height of the image and val3 is the number of channels for the image."
      ]
    },
    {
      "metadata": {
        "id": "4PLmTIy8846U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Transposing an Image\n",
        "\n",
        "* In this exercise we will read an image using tensorflow and then transpose it using tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "fUQBr1HJ-2_F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Lets download an image to play with\n",
        "! wget https://upload.wikimedia.org/wikipedia/commons/5/54/TaraxacumOfficinaleSeed.JPG\n",
        "! wget https://www.planwallpaper.com/static/images/880665-road-wallpapers.jpg\n",
        "! wget http://files.all-free-download.com//downloadfiles/wallpapers/2560_1600/at_the_beach_wallpaper_beaches_nature_1247.jpg\n",
        "! wget https://wallpaper-house.com/data/out/1/wallpaper2you_12642.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6-Yfbpc-4XD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check whether is image is downloaded, you can skip this step if you want\n",
        "! ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EANgCsZdiQdR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.image as mp_img\n",
        "import matplotlib.pyplot as plot\n",
        "import os\n",
        "\n",
        "\n",
        "filename = \"./TaraxacumOfficinaleSeed.JPG\"\n",
        "\n",
        "image = mp_img.imread(filename)\n",
        "\n",
        "print (\"image shape is:\", image.shape)\n",
        "print (\"image array:\", image)\n",
        "\n",
        "plot.imshow(image)\n",
        "plot.show()\n",
        "\n",
        "x = tf.Variable(image, name='image')\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  # Note that here in perm [1,0,2] we are swapping 0 and 1 indices or x with y\n",
        "  transpose = tf.transpose(x, perm = [1,0,2])\n",
        "  \n",
        "  result = sess.run(transpose)\n",
        "  \n",
        "  print (\"transposed image shape:\", result.shape)\n",
        "  \n",
        "  plot.imshow(result)\n",
        "  plot.show()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JnrtQ_cynXeR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Resizing image using tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "H1IYvFq0JwVr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Without tf.stack() method\n"
      ]
    },
    {
      "metadata": {
        "id": "ha_2SZe4nbsm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "original_image_list = [\"./880665-road-wallpapers.jpg\", \n",
        "                       \"./TaraxacumOfficinaleSeed.JPG\",\n",
        "                       \"./wallpaper2you_12642.jpg\",\n",
        "                       \"./at_the_beach_wallpaper_beaches_nature_1247.jpg\"]\n",
        "\n",
        "# Make a queue of file names including all the images specified.\n",
        "filename_queue = tf.train.string_input_producer(original_image_list)\n",
        "\n",
        "# Read an entire image file.\n",
        "image_reader = tf.WholeFileReader()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # Coordinate the loading of image files. It manages the thread in a queue\n",
        "    coord = tf.train.Coordinator()\n",
        "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
        "\n",
        "    image_list = [];\n",
        "    for i in range(len(original_image_list)):\n",
        "        # Read a whole file from the queue, the first returned value in the tuple is the\n",
        "        # filename which we are ignoring.\n",
        "        _, image_file = image_reader.read(filename_queue)\n",
        "\n",
        "        # Decode the image as a JPEG file, this will turn it into a Tensor which we can\n",
        "        # then use in training.\n",
        "        image = tf.image.decode_jpeg(image_file)\n",
        "\n",
        "        # Get a tensor of resized images.\n",
        "        image = tf.image.resize_images(image, [224, 224])\n",
        "        image.set_shape((224, 224, 3))\n",
        "\n",
        "        # Get an image tensor and print its value.\n",
        "        image_array = sess.run(image)\n",
        "        print (image_array.shape)\n",
        "\n",
        "        Image.fromarray(image_array.astype('uint8'), 'RGB').show()\n",
        "\n",
        "        # The expand_dims adds a new dimension\n",
        "        image_list.append(tf.expand_dims(image_array, 0))\n",
        "\n",
        "    # Finish off the filename queue coordinator.\n",
        "    coord.request_stop()\n",
        "    coord.join(threads)\n",
        "\n",
        "    index = 0\n",
        "\n",
        "    # Write image summary\n",
        "    summary_writer = tf.summary.FileWriter('./m4_example2', graph=sess.graph)\n",
        "\n",
        "    for image_tensor in image_list:\n",
        "        summary_str = sess.run(tf.summary.image(\"image-\" + str(index), image_tensor))\n",
        "        summary_writer.add_summary(summary_str)\n",
        "        index += 1\n",
        "\n",
        "    summary_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SlyBguAus9e8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Visualize Tensorboard here : https://colab.research.google.com/drive/1ndNCQmID2x7Gk_gNGer2k4yz4EJ1ZuG0\n",
        "\n",
        "* Tensor flow often deals with list of images in 4-D tensor, with the first dimension as the number of the images in that list. For example (10[number of images], 6[width], 6[height], 3[number of channels])\n",
        " \n",
        " * For the Images to be represented as 4D tensors, all images should have the same size.\n",
        " \n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "S9hCiH0DJ-PM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### With tf.stack() method\n",
        "\n",
        "* this method is used to transform a tensor of rank r to a tensor of rank r+1 tensor\n",
        "* we will run the same above code using tf.stack() method"
      ]
    },
    {
      "metadata": {
        "id": "exYXvw9ts87S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "original_image_list = [\"./880665-road-wallpapers.jpg\", \n",
        "                       \"./TaraxacumOfficinaleSeed.JPG\",\n",
        "                       \"./wallpaper2you_12642.jpg\",\n",
        "                       \"./at_the_beach_wallpaper_beaches_nature_1247.jpg\"]\n",
        "\n",
        "# Make a queue of file names including all the images specified.\n",
        "filename_queue = tf.train.string_input_producer(original_image_list)\n",
        "\n",
        "# Read an entire image file.\n",
        "image_reader = tf.WholeFileReader()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # Coordinate the loading of image files. It manages the thread in a queue\n",
        "    coord = tf.train.Coordinator()\n",
        "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
        "\n",
        "    image_list = [];\n",
        "    for i in range(len(original_image_list)):\n",
        "        # Read a whole file from the queue, the first returned value in the tuple is the\n",
        "        # filename which we are ignoring.\n",
        "        _, image_file = image_reader.read(filename_queue)\n",
        "\n",
        "        # Decode the image as a JPEG file, this will turn it into a Tensor which we can\n",
        "        # then use in training.\n",
        "        image = tf.image.decode_jpeg(image_file)\n",
        "\n",
        "        # Get a tensor of resized images.\n",
        "        image = tf.image.resize_images(image, [224, 224])\n",
        "        image.set_shape((224, 224, 3))\n",
        "\n",
        "        # Get an image tensor and print its value.\n",
        "        image_array = sess.run(image)\n",
        "        print (image_array.shape)\n",
        "\n",
        "        # Convert a numpy array of kind(224,224,3) to a tensor of shape (224,224,3)\n",
        "        image_tensor = tf.stack(image_array)\n",
        "\n",
        "        # The list will now simply holds the image tensor\n",
        "        image_list.append(image_tensor)\n",
        "\n",
        "    # Finish off the filename queue coordinator.\n",
        "    coord.request_stop()\n",
        "    coord.join(threads)\n",
        "\n",
        "    # now lets convert all tensors to a  single tensor of 4-d using stack() command\n",
        "    # 4 images can be accessed with 4-D tensor as (0,224,224,3), (1,224,224,3),etv\n",
        "    \n",
        "    image_tensor = tf.stack(image_list)\n",
        "    print(image_tensor)\n",
        "    \n",
        "    \n",
        "    summary_writer = tf.summary.FileWriter('./example_4', graph = sess.graph)\n",
        "    \n",
        "    # write all images in a one go\n",
        "    \n",
        "    summary_str = sess.run(tf.summary.image(\"images\",image_tensor,max_outputs=4))\n",
        "    summary_writer.add_summary(summary_str)   \n",
        "    \n",
        "    summary_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3x_iE4uEOeJL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using K- Nearest Neighbors for digit recognition\n",
        "\n",
        "* Will introduce the MNIST handwritten datasets\n",
        "\n",
        "* Understand KNN machine learning algorithm\n",
        "\n",
        "* Implement KNN algo to detect handwritten digits from 0-9\n"
      ]
    },
    {
      "metadata": {
        "id": "5JK1QfVqPcbO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### MNIST\n",
        "\n",
        "* MNIST  is a handwrtten digit database or dataset.\n",
        "* it stands for Modifies National Institute of standards and technology\n",
        "* each image in the dataset is a grayscale image\n",
        "* you can download the dataset from [link](http://yann.lecun.com/exdb/mnist/) \n",
        "* every image has size (28,28), which gives 784 pixels in each image.\n",
        "* since it is a single channel it contains the intensity"
      ]
    },
    {
      "metadata": {
        "id": "JP9yohGGQshP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### KNN\n",
        "\n",
        "* It is a supervised machine learning algorithm which uses the training data to find what is similar to the current sample.\n",
        "\n",
        "*  It uses the entire dataset as its model.\n",
        "\n",
        "* Each element in the dataset have a label attached to it.\n",
        "\n",
        "*  When a new input is feeded KNN tries to find the most similar image in the dataset.\n",
        "\n",
        "* it does so using distance measurements, i.e how far away one data point is from another data point.\n",
        "\n",
        "* most of the distance measurements are like euclidean distance, hamming distance(remember Networking :D), etc\n",
        "\n",
        " ##### Distance Measures:\n",
        " \n",
        " * euclidean distance. it is like a displacement, i.e join directly two points and find the distance.\n",
        " \n",
        " ![Image](https://github.com/Gaurav-Pande/MLCC/blob/master/tensorflow_basics/assets/2.png)\n",
        " \n",
        " * with grayscale images we use L1 distance(snake distance): \n",
        " \n",
        " ![Image](https://github.com/Gaurav-Pande/MLCC/blob/master/tensorflow_basics/assets/3.png)\n",
        " \n",
        " * you can observe that euclidean is more shorter than L1."
      ]
    },
    {
      "metadata": {
        "id": "qY2tPebyVRU5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### KNN implementation steps:\n",
        "\n",
        "1.  Getting MNIST images from dataset and test images in batches to tensorflow libraries\n",
        "\n",
        "2.  Calculating L1 distance(find the distance between test digit and all training digits)\n",
        "\n",
        "3.  Running algorithm:  Predict labels of all test data and measure accuracy.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "w2_xESRgVJTi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# Store the MNIST data in mnist_data directory\n",
        "# remember here the one_hot=True means that label will be represented a vector\n",
        "# of 10 elements, so for example, 4 will be represented as\n",
        "# [0,0,0,0,1,0,0,0,0,0] (note that 4 is at the index 4 of the list)\n",
        "\n",
        "mnist = input_data.read_data_sets(\"mnist_data/\", one_hot=True)\n",
        "\n",
        "training_digits, training_labels = mnist.train.next_batch(5000)\n",
        "test_digits, test_labels = mnist.test.next_batch(200)\n",
        "\n",
        "# we have no idea how many images we are going to pass in,so first param in the \n",
        "# placeholder [None, 784] indicates the index of the image, and the second \n",
        "# parameter in 784 indicates vector of 784 values, because we represent the images\n",
        "# as a vector.\n",
        "training_digits_pl = tf.placeholder(\"float\", [None, 784])\n",
        "\n",
        "test_digit_pl = tf.placeholder(\"float\", [784])\n",
        "\n",
        "# Nearest Neighbor calculation using L1 distance\n",
        "l1_distance = tf.abs(tf.add(training_digits_pl, tf.negative(test_digit_pl)))\n",
        "\n",
        "distance = tf.reduce_sum(l1_distance, axis=1)\n",
        "\n",
        "# Prediction: Get min distance index (Nearest neighbor)\n",
        "pred = tf.arg_min(distance, 0)\n",
        "\n",
        "accuracy = 0.\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    # loop over test data\n",
        "    for i in range(len(test_digits)):\n",
        "        # Get nearest neighbor\n",
        "        nn_index = sess.run(pred, \\\n",
        "        \tfeed_dict={training_digits_pl: training_digits, test_digit_pl: test_digits[i, :]})\n",
        "\n",
        "        # Get nearest neighbor class label and compare it to its true label\n",
        "        print(\"Test\", i, \"Prediction:\", np.argmax(training_labels[nn_index]), \\\n",
        "            \"True Label:\", np.argmax(test_labels[i]))\n",
        "\n",
        "        # Calculate accuracy\n",
        "        if np.argmax(training_labels[nn_index]) == np.argmax(test_labels[i]):\n",
        "            accuracy += 1./len(test_digits)\n",
        "\n",
        "    print(\"Done!\")\n",
        "    print(\"Accuracy:\", accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
